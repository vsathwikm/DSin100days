{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Performance\n",
    "\n",
    "One of the key goals of Machine Learning is to create a model in such a way that we have confidence that the model we build will predict new samples with a similar degree of accuracy on the set of data for which the model was evaluated. Without this\n",
    "confidence, the model’s predictions are useless. \n",
    "\n",
    "On a practical note, all model building efforts are constrained by the existing data. For many problems, the data may have a limited number of samples, may be of less-than-desirable quality, and/or may be unrepresentative of future samples. While there are ways to build predictive models on small data sets,  we will assume that data quality is sufficient and that it is representative of the entire sample population.\n",
    "\n",
    "The techniques of preparing the data in the above manner is explained in the Data Preparation course. \n",
    "\n",
    "Working under these assumptions about the dataset, we must use the data at hand to find the best predictive model. Almost all predictive modeling techniques have tuning parameters that enable the model to flex to find the structure in the data. Hence, we must use the existing data to identify settings for the model’s parameters that yield the best and most realistic predictive performance. This is known as model tuning.\n",
    "\n",
    "In this course, We will learn about:\n",
    "\n",
    "1. Overfitting.\n",
    "2. Bias-Variance trade-off\n",
    "3. Techniques to prepare data for validating model perfromance\n",
    "4. Model Tuning parameters\n",
    "5. Model Evaluation\n",
    "\n",
    "\n",
    "## Overfitting problem\n",
    "\n",
    "There now exist many techniques that can learn the structure of a set of data so well that when the model is applied to the data on which the model was built, it correctly predicts every sample. In addition to learning the general patterns in the data, the model has also learned the characteristics of each sample’s unique noise. This type of model is said to be over-fit and will usually have poor accuracy when predicting a new sample.\n",
    "\n",
    "\n",
    "In the example below, the blue curve represents the model and the red dots represent the training data points:\n",
    "\n",
    "<img src=\"../images/overfitting.png\", style=\"width: 700px;\"> \n",
    "\n",
    "As you can see from the above that the curve tries to fit all the data points in the training dataset.\n",
    "\n",
    "Overfitting means that the Model fits the training data very well including the noise in the dataset to such an extent that when we try to predict the new data with the model it performs very poorly. In other words, the model has been very flexible to fit the training dataset so as to lose the understanding of the generic pattern in the overall data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Press play button and submit to contunue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hint\n",
    "\n",
    "Press play and then submit, to proceed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continue\n"
     ]
    }
   ],
   "source": [
    "# ref_assert\n",
    "\n",
    "try:\n",
    "    test = True\n",
    "    if test == True:\n",
    "        ref_assert_var = True\n",
    "        print('continue')\n",
    "    else:\n",
    "        ref_assert_var = False\n",
    "        print('Please follow the instructions given and use the same variables provided in the instructions. ')\n",
    "except Exception:\n",
    "    print('Please follow the instructions given and use the same variables provided in the instructions. ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias - Variance Trade-off\n",
    "\n",
    "In order to minimize the expected test error, we need to select a statistical learning method that simultaneously achieves\n",
    "low variance and low bias.\n",
    "\n",
    "\n",
    "### Variance\n",
    "\n",
    "Variance refers to the amount by which function f would change if we\n",
    "estimated it using a different training data set. Since the training data\n",
    "are used to fit the statistical learning method, different training data sets\n",
    "will result in a different function f. But ideally the estimate for f should not vary\n",
    "too much between training sets. However, if a method has high variance\n",
    "then small changes in the training data can result in large changes in estimated f. In\n",
    "general, more flexible statistical methods have higher variance.\n",
    "\n",
    "\n",
    "### Bias\n",
    "\n",
    "Bias refers to the error that is introduced by approximating\n",
    "a real-life problem, which may be extremely complicated, by a much\n",
    "simpler model. For example, linear regression assumes that there is a linear\n",
    "relationship between Y and X1,X2, . . . , Xp. It is unlikely that any real-life\n",
    "problem truly has such a simple linear relationship, and so performing linear\n",
    "regression will undoubtedly result in some bias in the estimate of f.\n",
    "\n",
    "\n",
    "### Bias-Variance Trade-off\n",
    "\n",
    "In the diagram below, as the complexity increases, the variance increases and bias decreases.\n",
    "This corresponds to the total error (= train_error + test_error) varying as a curve. It first decreases as the complexity grows to a point where the accuracy of the model is optimal. Once it reaches a point where the model starts overfitting the train data, the total error increases again.\n",
    "\n",
    "The point where the total error is minimal is the trade-off point between bias and variance. This will correspond to the most accurate and optimal model for the train and test dataset.\n",
    "\n",
    "<img src=\"../images/complexity-error.png\", style=\"width: 700px;\"> \n",
    "\n",
    "\n",
    "Reference - Introduction to Statistical Learning using R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pre-loaded code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continue\n"
     ]
    }
   ],
   "source": [
    "# ref_assert\n",
    "\n",
    "try:\n",
    "    test = True\n",
    "    if test == True:\n",
    "        ref_assert_var = True\n",
    "        print('continue')\n",
    "    else:\n",
    "        ref_assert_var = False\n",
    "        print('Please follow the instructions given and use the same variables provided in the instructions. ')\n",
    "except Exception:\n",
    "    print('Please follow the instructions given and use the same variables provided in the instructions. ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Train- Test Split\n",
    "\n",
    "In order to tune the model to find the structure in the data in the best possible fashion, we must use the existing data to identify settings for the model’s parameters that yield the best and most realistic predictive performance.\n",
    "\n",
    "Traditionally, this has been achieved by splitting the existing data into training and test sets. The training set is used\n",
    "to build and tune the model and the test set is used to estimate the model’s predictive performance. Modern approaches to model building split the data into multiple training and testing sets, which have been shown to often find more optimal tuning parameters and give a more accurate representation of the model’s predictive performance.\n",
    "\n",
    "To avoid over-fitting, we use a general model building approach that encompasses model tuning and model evaluation\n",
    "with the ultimate goal of finding the reproducible structure in the data. This approach entails splitting existing data into distinct sets for the purposes of tuning model parameters and evaluating model performance. The choice of data splitting method depends on characteristics of the existing data such as its size and structure.\n",
    "\n",
    "When a large amount of data is at hand, a set of samples can be set aside to evaluate the final model. The “training” data set is the general term for the samples used to create the model, while the “test” or “validation”data set is used to qualify performance.\n",
    "\n",
    "## Exercise\n",
    "\n",
    "In the following exercise, write code to create a train-test split using sklearn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "\n",
    "#load boston dataset using boston_dataset.feature_names\n",
    "boston_dataset = datasets.load_boston()\n",
    "boston_data = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)\n",
    "boston_data['MEDV'] = boston_dataset.target\n",
    "\n",
    "#create X and y as input and output vectors\n",
    "X = boston_data[['CRIM', 'ZN', 'CHAS', 'NOX', 'RM', 'DIS', 'RAD', 'PTRATIO', 'B', 'LSTAT']]\n",
    "y = boston_data[['MEDV']]\n",
    "\n",
    "# Write code below to create train-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hint\n",
    "Use sklearn.modelselection. train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.05059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.449</td>\n",
       "      <td>6.389</td>\n",
       "      <td>4.7794</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.5</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>0.04301</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.413</td>\n",
       "      <td>5.663</td>\n",
       "      <td>10.5857</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>382.80</td>\n",
       "      <td>8.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>0.40771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.507</td>\n",
       "      <td>6.164</td>\n",
       "      <td>3.0480</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.4</td>\n",
       "      <td>395.24</td>\n",
       "      <td>21.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.61282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.096</td>\n",
       "      <td>3.7598</td>\n",
       "      <td>4.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>248.31</td>\n",
       "      <td>20.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>0.57834</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.575</td>\n",
       "      <td>8.297</td>\n",
       "      <td>2.4216</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>384.54</td>\n",
       "      <td>7.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  CHAS    NOX     RM      DIS  RAD  PTRATIO       B  LSTAT\n",
       "84   0.05059   0.0   0.0  0.449  6.389   4.7794  3.0     18.5  396.90   9.62\n",
       "354  0.04301  80.0   0.0  0.413  5.663  10.5857  4.0     22.0  382.80   8.05\n",
       "221  0.40771   0.0   1.0  0.507  6.164   3.0480  8.0     17.4  395.24  21.46\n",
       "34   1.61282   0.0   0.0  0.538  6.096   3.7598  4.0     21.0  248.31  20.34\n",
       "267  0.57834  20.0   0.0  0.575  8.297   2.4216  5.0     13.0  384.54   7.44"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=4)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continue\n"
     ]
    }
   ],
   "source": [
    "# ref_assert\n",
    "\n",
    "try:\n",
    "    test = True\n",
    "    if test == True:\n",
    "        ref_assert_var = True\n",
    "        print('continue')\n",
    "    else:\n",
    "        ref_assert_var = False\n",
    "        print('Please follow the instructions given and use the same variables provided in the instructions. ')\n",
    "except Exception:\n",
    "    print('Please follow the instructions given and use the same variables provided in the instructions. ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-fold Cross Validation\n",
    "\n",
    "In the previous lesson, we saw how to split the large dataset as the “training” data set and the “test” or “validation”data set to qualify performance.\n",
    "\n",
    "However, when the number of samples is not large, a strong case can be made that a test set should be avoided because every sample may be needed for model building. Additionally, the size of the test set may not have sufficient power or precision to make reasonable judgements. Resampling methods, such as cross-validation, can be used to produce appropriate estimates of model performance using the training set.\n",
    "\n",
    "Generally, resampling techniques for estimating model performance operate similarly: a subset of samples are used to fit a model and the remaining samples are used to estimate the efficacy of the model. This process is repeated multiple times and the results are aggregated and summarized. The differences in techniques usually center around the method in which subsamples are chosen.\n",
    "\n",
    "In Cross Validation, the samples are randomly partitioned into k sets of roughly equal size. A model is fit using the all samples except the first subset (called the first fold). The held-out samples are predicted by this model and used to estimate\n",
    "performance measures. The first subset is returned to the training set and  procedure repeats with the second subset held out, and so on. The k resampled estimates of performance are summarized (usually with the mean and standard error) and used to understand the relationship between the tuning parameter(s) and model utility.\n",
    "\n",
    "A leave-one-out cross-validation (LOOCV), is the special case where k is the number of samples. In this case, since only one sample is held-out at a time, the final performance is calculated from the k individual held-out predictions. For example, if 10-fold cross-validation was repeated five times, 50 different held-out sets would be used to estimate model efficacy. The choice of k is usually 5 or 10, but there is no formal rule. As k gets larger, the difference in size between the training set and the resampling subsets gets smaller. As this difference decreases, the bias of the technique becomes smaller (i.e., the bias is smaller for k = 10 than k = 5). In this  context, the bias is the difference between the estimated and true values of performance.\n",
    "\n",
    "\n",
    "### Exercise\n",
    "\n",
    "In the code below, check how KFold from sklearn has been used to make the CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=2, random_state=None, shuffle=False)\n",
      "TRAIN: [2 3] TEST: [0 1]\n",
      "TRAIN: [0 1] TEST: [2 3]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "y = np.array([1, 2, 3, 4])\n",
    "kf = KFold(n_splits=2)\n",
    "kf.get_n_splits(X)\n",
    "print(kf)  \n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continue\n"
     ]
    }
   ],
   "source": [
    "# ref_assert\n",
    "\n",
    "try:\n",
    "    test = True\n",
    "    if test == True:\n",
    "        ref_assert_var = True\n",
    "        print('continue')\n",
    "    else:\n",
    "        ref_assert_var = False\n",
    "        print('Please follow the instructions given and use the same variables provided in the instructions. ')\n",
    "except Exception:\n",
    "    print('Please follow the instructions given and use the same variables provided in the instructions. ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeated Training/Test Splits\n",
    "\n",
    "Repeated training/test splits is also known as “leave-group-out crossvalidation” or “Monte Carlo cross-validation.” This technique simply creates multiple splits of the data into modeling and prediction sets. The proportion of the data going into each subset and the number of repetitions are controlled by the Data Scientist. The bias of the resampling technique decreases as the amount of data in the subset approaches the amount in the modeling set. A good rule of thumb is about 75–80%. Higher proportions are a good idea if the number of repetitions is large.\n",
    "\n",
    "Increasing the repetitions of the number of subsets has the effect of decreasing the uncertainty of the performance estimates.\n",
    "For example, to get a gross estimate of model performance, 25 repetitions will be adequate if the user is willing to accept some instability in the resulting values. However, to get stable estimates of performance, it is suggested to choose a larger number of repetitions (say 50–200).\n",
    "\n",
    "### The Bootstrap\n",
    "\n",
    "The Bootstrap is another re-sampling technique to improve model performance. A bootstrap sample is a random sample of the data taken with replacement. After a data point is selected for the subset, it is still available for further selection. The bootstrap sample is the same size as the original data set. As a result, some samples will be represented multiple times in the bootstrap sample while others will not be selected at all. The samples not selected are usually referred to as the “out-of-bag” samples. For a given iteration of bootstrap resampling, a model is built on the selected samples and is used to predict the out-of-bag samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continue\n"
     ]
    }
   ],
   "source": [
    "# ref_assert\n",
    "\n",
    "try:\n",
    "    test = True\n",
    "    if test == True:\n",
    "        ref_assert_var = True\n",
    "        print('continue')\n",
    "    else:\n",
    "        ref_assert_var = False\n",
    "        print('Please follow the instructions given and use the same variables provided in the instructions. ')\n",
    "except Exception:\n",
    "    print('Please follow the instructions given and use the same variables provided in the instructions. ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning parameters\n",
    "\n",
    "Various ML libraries provide several implementation of the ML algorithms.\n",
    "With each algorithm, the libraries provide different options such as parameters to tune the model to achieve maximum efficiency.\n",
    "These parameters have to be determined by evaluating the performance of the model and tuning the parameters accordingly.\n",
    "\n",
    "For example, in the KNN algorithm for regression, the optimal 'k' value needs to be determined by tuning the algorithm with various k values and identifying the efficiency of the resulting models. There are several approaches to evaluate the performance or efficiency of the models, which will be dealt with in the next lesson in this course.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#hit playbutton to continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continue\n"
     ]
    }
   ],
   "source": [
    "# ref_assert\n",
    "\n",
    "try:\n",
    "    test = True\n",
    "    if test == True:\n",
    "        ref_assert_var = True\n",
    "        print('continue')\n",
    "    else:\n",
    "        ref_assert_var = False\n",
    "        print('Please follow the instructions given and use the same variables provided in the instructions. ')\n",
    "except Exception:\n",
    "    print('Please follow the instructions given and use the same variables provided in the instructions. ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the data\n",
    "\n",
    "The performance of the model could be improved by finetuning the data used for training the model. Some of the techniques include:\n",
    "\n",
    "1. Removing Predictors\n",
    "2. Removing correlations\n",
    "3. Creating Computed Variables\n",
    "\n",
    "### Removing Predictors\n",
    "\n",
    "There are potential advantages to removing predictors prior to modeling. First, fewer predictors means decreased computational time and complexity. Second, if two predictors are highly correlated, this implies that they are measuring the same underlying information. Removing one should not compromise the performance of the model and might lead to a more parsimonious and interpretable model. Third, some models can be crippled by predictors with degenerate distributions. In these cases, there can be a significant improvement in model performance and/or stability without the problematic variables.\n",
    "\n",
    "Consider a predictor variable that has a single unique value; we refer to this type of data as a zero variance predictor. For some models, such an uninformative variable may have little effect on the calculations. A model such as linear regression\n",
    "would find these data problematic and is likely to cause an error in the computations. These data have no information and can easily be discarded. Similarly, some predictors might have only a handful of unique values that occur with very low frequencies. These “near-zero variance predictors” may have a single value for the vast majority of the samples. They could be treated in a similar way.\n",
    "\n",
    "\n",
    "### Between-Predictor Correlations\n",
    "\n",
    "Collinearity is the technical term for the situation where a pair of predictor variables have a substantial correlation with each other. It i  also possible to have relationships between multiple predictors at once (calle multicollinearity).\n",
    "\n",
    "For example, in a housing price dataset, the crime rate information might have a linear colinearity with say data on how secure the residents feel. Such information must be cleaned in such a way that there is a unique predictor without correlations beween predictors. \n",
    "\n",
    "\n",
    "\n",
    "### Creating Computed Variables\n",
    "\n",
    "In some cases, a computed variable (feature) with multiple input variables might provide better model compured to the individual variables included as it is. For example in a stock market dataset, a variable with the average of last 5 days gives better meaning to the dataset. (This is called moving averages). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continue\n"
     ]
    }
   ],
   "source": [
    "# ref_assert\n",
    "\n",
    "try:\n",
    "    test = True\n",
    "    if test == True:\n",
    "        ref_assert_var = True\n",
    "        print('continue')\n",
    "    else:\n",
    "        ref_assert_var = False\n",
    "        print('Please follow the instructions given and use the same variables provided in the instructions. ')\n",
    "except Exception:\n",
    "    print('Please follow the instructions given and use the same variables provided in the instructions. ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R-squared:\n",
    "\n",
    "R-squared is a value between 0 and 1.0 to measure how well the dependent variables are effectively modeling the target variable. The higher the value, the better that the dependent variables explain the fit. If the R-squared is a low value closer to 0.0 it shows that the predictor variable selected is not a good indicator of the target variable. To increase the R-squared value and get better fit or predictions, the best way is to increase the number of independent variables (also called Feature Engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continue\n"
     ]
    }
   ],
   "source": [
    "# ref_assert\n",
    "\n",
    "try:\n",
    "    test = True\n",
    "    if test == True:\n",
    "        ref_assert_var = True\n",
    "        print('continue')\n",
    "    else:\n",
    "        ref_assert_var = False\n",
    "        print('Please follow the instructions given and use the same variables provided in the instructions. ')\n",
    "except Exception:\n",
    "    print('Please follow the instructions given and use the same variables provided in the instructions. ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
